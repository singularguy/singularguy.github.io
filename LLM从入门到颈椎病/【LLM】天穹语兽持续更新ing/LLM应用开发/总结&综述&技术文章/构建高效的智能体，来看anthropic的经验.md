# 构建高效的智能体，来看anthropic的经验
* * *

created: 2025-01-24T00:20 updated: 2025-01-26T02:05
---------------------------------------------------

> _**作者: 北方的郎**_
> 
> _\*\*原文: \*\*_[_**https://mp.weixin.qq.com/s/I\_ZtBrOrudgydS3o6\_Crqg**_](https://mp.weixin.qq.com/s/I_ZtBrOrudgydS3o6_Crqg)

近日看到anthropic公司的[Building effective agents](https://link.zhihu.com/?target=https%3A//www.anthropic.com/research/building-effective-agents),感觉写的非常不错.

这篇文章讨论了智能体(Agents)在大语言模型(LLM)中的应用,强调了它们在处理开放性、难以预测任务中的优势,特别是在客户支持和编码自动化领域. 智能体通过独立规划和执行任务,结合环境反馈不断优化执行过程,并在遇到障碍时暂停以获取用户反馈. 文章提到,设计高效的智能体不仅需要简洁的设计、透明的规划过程,还需精心设计工具和接口. 作者强调在开发过程中应进行充分的测试和优化,确保智能体能够可靠地完成任务,同时提出了设计智能体时的[最佳实践](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5&zhida_source=entity)和相关挑战.

我把它翻译了一下,方便大家阅读,以下是译文:

* * *

在过去的一年中,我们与数十个团队合作,跨多个行业构建大语言模型(LLM)智能体. 成功的实施案例表明,最成功的实现并不是依赖复杂的框架或专业的库,而是采用简单、可组合的模式来构建.

在这篇文章中,我们分享了与客户合作和自己构建智能体过程中的经验,并为开发者提供了关于如何构建高效智能体的实用建议.

什么是智能体？
-------

“智能体”可以有多种定义. 一些客户将智能体定义为完全自主的系统,这些系统在长时间内独立运行,使用各种工具来完成复杂任务. 其他人则将智能体用来描述遵循预定义工作流的实施方式. 在Anthropic,我们将所有这些变体归类为“[智能体系统](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F&zhida_source=entity)”(agentic systems),但在架构上,我们区分了工作流(**workflows**)与智能体(**agents**)之间的重要区别:

*   **工作流(**workflows**)** 是通过预定义代码路径协调LLM和工具的系统.
*   **智能体(**agents**)** 是LLM根据自身需求动态控制其过程和工具使用的系统,保持对任务完成方式的控制.

在下面的部分,我们将详细探讨这两种类型的智能体系统. 在附录1(《实践中的智能体》)中,我们描述了客户在以下两个领域中发现这些系统特别有价值的应用.

什么时候使用(以及不使用)智能体？
-----------------

在使用LLM构建应用时,我们建议先找到最简单的解决方案,只有在必要时才增加复杂性. 这可能意味着根本不构建智能体系统. 智能体系统通常通过牺牲延迟和成本来提高任务表现,因此你应该考虑这种权衡是否合理.

当更多复杂性是必要时,工作流为明确定义的任务提供可预测性和一致性,而智能体在需要灵活性和大规模[模型驱动](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E6%A8%A1%E5%9E%8B%E9%A9%B1%E5%8A%A8&zhida_source=entity)决策时更为合适. 然而,对于许多应用,优化单一的LLM调用并结合检索和上下文示例通常已足够.

何时及如何使用框架？
----------

有许多框架可以简化智能体系统的实现,包括:

*   LangChain的[LangGraph](https://link.zhihu.com/?target=https%3A//langchain-ai.github.io/langgraph/)；
*   Amazon Bedrock的[AI Agent framework](https://link.zhihu.com/?target=https%3A//aws.amazon.com/bedrock/agents/)；
*   [Rivet](https://link.zhihu.com/?target=https%3A//rivet.ironcladapp.com/),一个拖放式图形界面LLM工作流构建工具；
*   [Vellum](https://link.zhihu.com/?target=https%3A//www.vellum.ai/),另一个用于构建和测试复杂工作流的GUI工具.

这些框架通过简化诸如调用LLM、定义和解析工具、以及[链式调用](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8&zhida_source=entity)等低级任务,帮助你快速上手. 然而,它们通常会增加额外的抽象层,可能会掩盖底层的提示和响应,导致调试变得更加困难. 它们还可能诱使开发者添加不必要的复杂性,而实际上一个更简单的设置就能满足需求.

我们建议开发者直接使用LLM API: 许多模式可以用几行代码实现. 如果使用框架,请确保你理解底层代码. 关于代码的错误假设是客户错误的常见来源.

参见我们的烹饪书,里面有一些示例实现.

构建模块、工作流和智能体(Building blocks, workflows, and agents)
----------------------------------------------------

在本节中,我们将探讨我们在生产中见过的智能体系统的常见模式. 我们将从我们的基础构建模块——增强型LLM开始,并逐步增加复杂性,从简单的组合工作流到自主智能体.

### 构建模块: 增强型LLM(Building block: The augmented LLM)

智能体系统的基本构建块是增强型LLM,具备检索、工具和记忆等增强功能. 我们当前的模型能够主动使用这些功能——生成自己的搜索查询,选择适当的工具,并确定要保留的信息.

![](1_构建高效的智能体，来看anthropic的经验_image.)

> 增强型LLM

我们建议专注于两个关键方面: 将这些能力量身定制以适应你的具体用例,并确保它们为LLM提供一个简洁且有良好文档支持的接口. 虽然有很多方式可以实现这些增强功能,但一种方法是通过我们最近发布的模型上下文协议,它允许开发者通过一个简单的客户端实现,集成日益增长的第三方工具生态系统.

接下来,我们假设每个LLM调用都可以访问这些增强功能.

### 工作流: 提示链式调用(Workflow: Prompt chaining)

![](构建高效的智能体，来看anthropic的经验_image.)

> 提示链式工作流

提示链式调用将任务分解成一系列步骤,每个LLM调用处理前一个调用的输出. 你可以在任何中间步骤添加程序检查(见下图中的“门控”)以确保过程正常进行.  
\*\*使用时机: \*\* 该工作流适用于任务可以轻松清晰地分解为固定子任务的情况. 主要目标是通过将每个LLM调用的任务简化来换取更高的准确性.

\*\*提示链式调用的典型应用: \*\*

*   生成市场营销文案,然后将其翻译成不同的语言.
*   编写文档大纲,检查大纲是否符合某些标准,然后根据大纲编写文档.

### 工作流: 路由(Workflow: Routing)

路由将输入分类,并将其引导至专门的后续任务. 此工作流有助于[关注点分离](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E5%85%B3%E6%B3%A8%E7%82%B9%E5%88%86%E7%A6%BB&zhida_source=entity),构建更为专业化的提示. 没有该工作流的情况下,优化一种输入类型可能会影响其他输入的表现.

![](3_构建高效的智能体，来看anthropic的经验_image.)

> 路由工作流

\*\*使用时机: \*\* 路由适用于复杂任务,在这些任务中存在明确的类别,更适合分别处理,并且分类可以通过LLM或更传统的分类模型/算法准确完成.

\*\*路由工作流的典型应用: \*\*

*   将不同类型的客户服务查询(一般问题、退款请求、技术支持)引导到不同的后续处理流程、提示和工具.
*   将简单/常见问题路由到较小的模型(如Claude 3.5 Haiku),而将复杂/不常见问题路由到更强大的模型(如Claude 3.5 Sonnet),以优化成本和速度.

### 工作流: 并行化(Workflow: Parallelization)

LLM有时可以同时处理一个任务,并将它们的输出进行程序化汇总. 此工作流,即并行化,具有两种关键变体:

*   \*\*分区: \*\* 将任务分解成可以并行处理的独立子任务.
*   \*\*投票: \*\* 多次运行相同任务,以获得不同的输出.

![](7_构建高效的智能体，来看anthropic的经验_image.)

> 并行化工作流

\*\*使用时机: \*\* 并行化适用于可以通过并行化提高速度的子任务,或者需要多个视角或尝试以获得更高[置信度](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E7%BD%AE%E4%BF%A1%E5%BA%A6&zhida_source=entity)的结果的情况. 对于具有多个考量的复杂任务,当每个考量由单独的LLM调用处理时,LLM通常表现更好,能够专注于每个特定方面.

\*\*并行化工作流的典型应用: \*\*

*   \*\*分区: \*\* 实施保护措施,让一个模型实例处理用户查询,另一个模型实例筛查不适当内容或请求. 这通常比让同一个LLM调用同时处理保护措施和核心响应效果更好.
*   \*\*投票: \*\* 评审一段代码中的漏洞,多个不同的提示评审并标记代码中的问题.
*   **评估是否内容不当**,多个提示评估不同的方面,或者使用不同的投票阈值平衡假阳性和假阴性.

### 工作流: 调度器-工作者(Workflow: Orchestrator-workers)

在调度器-工作者工作流中,一个中心LLM动态地将任务分解,分配给工作者LLM,并综合它们的结果.

![](5_构建高效的智能体，来看anthropic的经验_image.)

> 调度器-工作者工作流

\*\*使用时机: \*\* 该工作流非常适合复杂任务,其中无法预测所需的子任务(例如,在编码任务中,可能需要更改的文件数量以及每个文件的更改性质可能依赖于任务). 与并行化的地理相似性不同,关键的区别是它的灵活性——子任务不是预定义的,而是由调度器根据具体输入决定的.

\*\*调度器-工作者工作流的典型应用: \*\*

*   处理产品编码任务,涉及多次修改多个文件.
*   搜索任务,涉及从多个来源收集并分析信息以获取可能的相关信息.

### 工作流: 评估者-优化者(Workflow: Evaluator-optimizer)

在评估者-优化者工作流中,一个LLM调用生成响应,另一个LLM调用提供评估并在循环中反馈.

![](2_构建高效的智能体，来看anthropic的经验_image.)

> 评估者-优化者工作流

\*\*使用时机: \*\* 当我们有明确的评估标准,并且通过迭代优化能提供可度量的价值时,这个工作流特别有效. 适用的情况有两个标志: 首先,LLM响应在有人给出反馈时可以明显改善；其次,LLM能够提供这样的反馈. 这类似于人类写作者在编写文档时经过的迭代过程.

\*\*评估者-优化者工作流的典型应用: \*\*

*   文学翻译,其中存在翻译模型可能初次未能捕捉的细微差别,但评估者模型可以提供有用的反馈.
*   复杂的搜索任务,要求多轮搜索和分析以收集全面信息,评估者决定是否需要进一步搜索.

### 智能体

随着[大语言模型](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=3&q=%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B&zhida_source=entity)(LLM)在理解复杂输入、进行推理与规划、可靠地使用工具以及从错误中恢复方面的能力逐渐成熟,智能体(Agents)开始在生产环境中得到了广泛应用. 智能体的工作通常始于人类用户的指令或互动讨论. 一旦任务明确,智能体便能独立规划和执行任务,必要时会返回人类用户以获取更多信息或判断. 在执行过程中,智能体需要在每个步骤获取来自环境的“真实信息”(如工具调用结果或代码执行)以评估其进展. 智能体还可以在检查点或遇到障碍时暂停,并请求人类反馈. 任务通常在完成时终止,但常常也会设置停止条件(如最大迭代次数)以保持对过程的控制.

智能体能够处理复杂的任务,但它们的实现往往是直接的. 通常,它们只是基于环境反馈的循环,使用工具的LLM. 因此,设计工具集及其文档时,需要特别清晰和周到. 我们在附录2《[提示工程](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B&zhida_source=entity)与工具》中扩展了工具开发的最佳实践.

![](6_构建高效的智能体，来看anthropic的经验_image.)

> 自主智能体

\*\*何时使用智能体: \*\*

智能体适用于那些开放性问题,在这些问题中,预测所需步骤的数量既困难又不可能,或者不能硬编码一个固定路径. LLM可能需要执行多次操作,你必须对其决策有一定的信任. 智能体的自主性使其在可信环境中进行任务扩展时尤为理想.

智能体的自主性意味着更高的成本,并且可能会带来错误累积的风险. 我们建议在[沙盒](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E6%B2%99%E7%9B%92&zhida_source=entity)环境中进行广泛测试,并建立适当的安全防护措施.

\*\*智能体的应用示例: \*\*

以下示例来自我们的实际应用:

*   一个编码智能体,用于解决[SWE-bench tasks](https://link.zhihu.com/?target=https%3A//www.anthropic.com/research/swe-bench-sonnet),该任务涉及根据任务描述修改多个文件；
*   我们的[“computer use” reference implementation](https://link.zhihu.com/?target=https%3A//github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo),其中Claude使用计算机执行任务.

![](4_构建高效的智能体，来看anthropic的经验_image.)

> 编码智能体的高层流程

将这些模式组合和定制(Combining and customizing these patterns)
----------------------------------------------------

这些构建模块并非是预设的,它们是开发人员可以根据不同用例进行塑造和组合的常见模式. 成功的关键与任何LLM特性一样,是衡量性能并在实现中进行迭代. 重复一次: 你应该仅在能够显著改善结果时,才考虑增加复杂性.

总结
--

在LLM领域取得成功并不意味着构建最复杂的系统,而是构建最适合你需求的系统. 从简单的提示开始,通过全面评估进行优化,只有当更简单的解决方案不再满足需求时,才添加多步骤的智能体系统.

在实现智能体时,我们尝试遵循三个核心原则:

1.  保持智能体设计的简单性.
2.  优先考虑透明性,明确展示智能体的规划步骤.
3.  通过完善的工具文档和测试,精心设计智能体与计算机的接口(ACI).

框架可以帮助你快速入门,但不要犹豫,在转向生产阶段时减少抽象层次,使用基础组件进行构建. 通过遵循这些原则,你可以创建既强大又可靠、可维护、并且得到用户信任的智能体.

### 致谢

本文由Erik Schluntz和Barry Zhang编写. 本工作借鉴了我们在Anthropic构建智能体的经验,以及客户分享的宝贵见解,我们对此深表感谢.

附录1: 实践中的智能体
------------

我们与客户的合作揭示了智能体的两个特别有前景的应用场景,这些场景展示了上述模式的实际价值. 这两种应用都展示了智能体如何为需要对话和行动的任务提供最大价值,这些任务有明确的成功标准,能够进行反馈循环,并整合有意义的人类监督.

### A. 客户支持

客户支持结合了熟悉的聊天机器人界面和通过工具集成增强的能力. 这对于更开放性任务的智能体来说是一个自然的契合点,因为:

*   支持互动通常遵循对话流程,同时需要访问外部信息和执行操作；
*   可以通过工具集成来拉取客户数据、订单历史和知识库文章；
*   诸如发放退款或更新工单等操作可以通过编程处理；
*   成功可以通过用户定义的解决方案来明确衡量.

一些公司已经通过基于使用量的定价模型展示了这种方法的可行性,客户只为成功的解决方案付费,展现了他们对智能体有效性的信心.

### B. 编码智能体

在软件开发领域,LLM特性展示出了显著的潜力,其能力已经从代码补全发展到自主问题解决. 智能体特别有效的原因是:

*   代码解决方案可以通过[自动化测试](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95&zhida_source=entity)来验证；
*   智能体可以使用测试结果作为反馈进行迭代解决方案；
*   问题空间已经很好地定义和结构化；
*   输出质量可以客观衡量.

在我们的实现中,智能体现在可以仅凭拉取请求描述解决SWE-bench Verified基准中的真实GitHub问题. 然而,虽然自动化测试有助于验证功能,但人工评审对于确保解决方案与更广泛的系统要求一致仍然至关重要.

附录2: 提示工程与工具
------------

无论你正在构建哪种类型的智能体系统,工具都可能是智能体的重要组成部分. 工具使Claude能够通过指定工具的确切结构和定义,与外部服务和API进行交互. 当Claude做出回应时,如果它计划调用工具,它将在API响应中包含工具使用块. 工具的定义和规范应与总体提示一样,给予充分的提示工程关注. 在这一简短的附录中,我们描述了如何对工具进行提示工程.

通常,有几种方式可以指定相同的操作. 例如,你可以通过编写差异来指定文件编辑,或通过重写整个文件来指定. 对于结构化输出,你可以在Markdown中或在JSON中返回代码. 在软件工程中,这些差异是外观上的,可以无损地从一个格式转换到另一个格式. 然而,一些格式比其他格式更难为LLM编写. 编写差异需要知道在新代码编写之前,块头部有多少行正在改变. 与Markdown相比,在JSON中编写代码需要额外的转义换行符和引号.

我们对工具格式选择的建议如下:

*   给模型足够的令牌,以便它在编写之前有足够的思考空间.
*   保持格式接近模型在互联网上自然出现的文本.
*   确保没有格式“开销”,例如不需要准确计数成千上万行代码,或转义任何它编写的代码.

一个[经验法则](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E7%BB%8F%E9%AA%8C%E6%B3%95%E5%88%99&zhida_source=entity)是,考虑人机界面(HCI)的工作量,并计划为创建良好的智能体与计算机接口(ACI)投入相同的努力. 以下是如何做到这一点的一些思考:

*   从模型的角度出发,考虑工具的描述和参数是否足够明确,模型是否容易理解如何使用这个工具？如果不明确,可能模型也会感到困惑. 一个好的工具定义通常包括示例用法、边界情况、输入格式要求,以及与其他工具的明确区分.
*   如何更改参数名称或描述使其更加直观？想象这就像为团队中的初级开发人员写一个出色的文档字符串. 这一点在使用多个相似工具时尤为重要.
*   测试模型如何使用你的工具: 在我们的工作平台中运行许多示例输入,观察模型会犯哪些错误,并进行迭代.
*   设计防错机制: 修改参数,使得出错变得更加困难.

在为[SWE-bench](https://link.zhihu.com/?target=https%3A//www.anthropic.com/research/swe-bench-sonnet)构建智能体时,我们实际上花了更多的时间来优化工具,而不是整体提示. 例如,我们发现,在智能体移出[根目录](https://zhida.zhihu.com/search?content_id=251901965&content_type=Article&match_order=1&q=%E6%A0%B9%E7%9B%AE%E5%BD%95&zhida_source=entity)后,使用相对文件路径的工具容易出错. 为了解决这个问题,我们将工具修改为始终要求绝对文件路径——结果模型完美地使用了这种方法.