# 微调技术汇总
大模型微调技术汇总
---------

* * *

目录
--

1.  [全量微调](#%E4%B8%80%E5%85%A8%E9%87%8F%E5%BE%AE%E8%B0%83full-fine-tuning)
2.  [参数高效微调](#%E4%BA%8C%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83parameter-efficient-fine-tuning-peft)
3.  [提示优化技术](#%E4%B8%89%E6%8F%90%E7%A4%BA%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF)
4.  [进阶微调技术](#%E5%9B%9B%E8%BF%9B%E9%98%B6%E5%BE%AE%E8%B0%83%E6%8A%80%E6%9C%AF)
5.  [训练加速技术](#%E4%BA%94%E8%AE%AD%E7%BB%83%E5%8A%A0%E9%80%9F%E6%8A%80%E6%9C%AF)
6.  [应用选择指南](#%E5%85%AD%E5%BA%94%E7%94%A8%E9%80%89%E6%8B%A9%E6%8C%87%E5%8D%97)
7.  [总结与展望](#%E4%B8%83%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B)

* * *

一、全量微调（Full Fine-Tuning）
------------------------

### 1\. 基础概念

*   **定义**：解冻预训练模型全部参数，通过下游任务数据进行全局参数更新
*   **数学表达**：  
    \\(\\theta\_{\\text{new}} = \\theta\_{\\text{pre}} + \\eta \\nabla\_\\theta \\mathcal{L}(\\theta)\\)  
    其中 \\(\\eta\\) 为学习率，\\(\\mathcal{L}\\) 为损失函数

### 2\. SFT（Supervised Fine-Tuning）

*   **核心特性**：
    *   **数据要求**：人工标注的结构化指令数据
        
        ```text-plain
        # 典型数据格式
        {
          "instruction": "将以下句子翻译成英文",
          "input": "今天的天气非常好",
          "output": "The weather is excellent today"
        }
        ```
        
    *   **训练配置**：
        *   学习率：1 e-5 ~ 5 e-5
        *   批量大小：32-128
        *   训练轮数：1-3 epochs（防止过拟合）
*   **硬件需求**：

| 模型规模 | 显存需求（FP 32） | GPU 配置示例 |     |
| --- | --- | --- | --- |
| 7 B | 120 GB | 4×A 100（80 G） |     |
| 13 B | 240 GB | 8×A 100（80 G） |     |

* * *

二、参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）
-----------------------------------------------

### 1\. **LoRA（Low-Rank Adaptation）**

*   **核心原理**：  
    冻结原模型参数，通过低秩分解学习参数增量  
    \\(\\Delta W = A \\cdot B \\quad (A \\in \\mathbb{R}^{d \\times r}, B \\in \\mathbb{R}^{r \\times k})\\)  
    其中秩 \\(r \\ll d,k\\)，典型值 \\(r=8\\)
*   **参数效率**：

| 模型规模 | 原始参数量 | LoRA 参数量 | 压缩比 |
| --- | --- | --- | --- |
| 7 B | 7,000 M | 4.2 M | 0.06% |

### 2\. **Adapter Tuning**

*   **结构设计**：  
    在 Transformer 层间插入适配模块
    
    ```text-plain
    [输入] → [原FFN] → [Adapter] → [输出]
                ↓
            Down-Proj（降维）  
                ↓  
             ReLU激活  
                ↓  
            Up-Proj（恢复维度）
    ```
    
*   **典型配置**：
    *   瓶颈维度：64-256
    *   参数量占比：0.5-5%

### 3\. **Prefix Tuning**

*   **实现方式**：
    *   在输入序列前添加可训练的前缀向量
    *   每层可设置独立前缀（P-Tuning v 2）
*   **参数对比**：

| 方法  | 参数量（7 B 模型） | 显存占用 |
| --- | --- | --- |
| 全量微调 | 7,000 M | 120 GB |
| Prefix Tuning | 0.8 M | 18 GB |

### 4\. **BitFit**

*   **实现机制**：  
    仅更新模型中的偏置项参数
    
    ```text-plain
    # PyTorch伪代码
    for param in model.parameters():
        if 'bias' in param.name:
            param.requires_grad = True
        else:
            param.requires_grad = False
    ```
    
*   **参数量占比**：

| 模型架构 | 可训练参数比例 |
| --- | --- |
| Transformer | 0.08%-0.6% |

### 5\. **IA³（Infused Adapter by Inhibiting and Amplifying Inner Activations）**

*   **核心机制**：  
    通过学习缩放向量调控激活值  
    \\(\\text{输出} = (s \\cdot W) \\cdot x + b\\)  
    其中 \\(s\\) 为可学习缩放因子
*   **参数效率**：
    *   每个任务仅需约 7,000 参数（7 B 模型）

* * *

三、提示优化技术
--------

### 1\. **Prompt Tuning**

*   **技术演进**：

| 版本  | 特点  | 参数量（7 B 模型） |
| --- | --- | --- |
| Hard Prompt | 人工设计离散提示词 | 0   |
| Soft Prompt | 可训练连续向量 | 0.1 M |
| P-Tuning v 2 | 分层提示+深度提示 | 0.8 M |

### 2\. **Instruction Tuning**

*   **数据构建原则**：
    *   **多样化**：覆盖 200+任务类型
    *   **明确性**：指令需清晰无歧义
    *   **逻辑链**：包含逐步推理过程
*   **典型数据集**：
    *   FLAN（1,836 个任务）
    *   Super-NaturalInstructions（1,600 个任务）

* * *

四、进阶微调技术
--------

### 1\. **QLoRA**

*   **四大量化技术**：

| 技术名称 | 实现效果 |
| --- | --- |
| 4-bit NormalFloat | 最小化量化误差 |
| 双量化（Double Quant） | 二次压缩量化参数 |
| 分页优化器 | 防止显存溢出 |
| 统一内存管理 | CPU/GPU 显存动态调度 |

*   **性能对比**：

| 方法  | 训练速度（tokens/s） | 显存占用（7 B 模型） |
| --- | --- | --- |
| 全量微调 | 120 | 120 GB |
| QLoRA | 95  | 18 GB |

### 2\. **Delta Tuning**

*   **数学表达**：  
    \\(\\theta\_{\\text{new}} = \\theta\_{\\text{pre}} + \\Delta\\theta\\)  
    其中 \\(\\Delta\\theta\\) 通过参数高效方法学习
*   **方法分类**：  
    ![Delta Tuning分类](https://pic3.zhimg.com/80/v2-6b9c9d8c7a8c4f4d4e4e8d9e4b7c7d7a_720w.png)

### 3\. **Model Soup**

*   **实现步骤**：
    1.  训练多个微调模型（不同初始化/数据顺序）
    2.  对模型权重进行线性平均  
        \\(\\theta\_{\\text{soup}} = \\frac{1}{N}\\sum\_{i=1}^N \\theta\_i\\)
*   **性能提升**：
    *   在 ImageNet 上最高提升 38%准确率

### 4\. **RLHF（Reinforcement Learning from Human Feedback）**

*   **三阶段流程**：
    
    ```text-plain
    graph LR
      A[SFT Model] --> B[奖励模型训练]
      B --> C[PPO优化]
      C --> D[最终对齐模型]
    ```
    
*   **关键组件**：

| 组件  | 功能描述 |
| --- | --- |
| 奖励模型（RM） | 学习人类偏好评分函数 |
| PPO 算法 | 约束策略更新幅度 |
| KL 散度惩罚项 | 防止过度偏离初始策略 |

* * *

五、训练加速技术
--------

### 1\. **ZeRO（Zero Redundancy Optimizer）**

*   **三阶段优化**：

| 阶段  | 优化内容 | 显存节省（7 B 模型） |
| --- | --- | --- |
| Stage 1 | 优化器状态分区 | 30% |
| Stage 2 | 梯度分区 | 50% |
| Stage 3 | 参数分区 | 75% |

### 2\. **DeepSpeed**

*   **关键技术**：
    *   **3 D 并行**：
        
        ```text-plain
        graph TD
          数据并行 --> 流水线并行 --> 张量并行
        ```
        
    *   **显存优化**：
        *   激活检查点（Activation Checkpointing）
        *   梯度累积（Gradient Accumulation）

### 3\. **Gradient Checkpointing**

*   **工作原理**：
    
    ```text-plain
    # PyTorch实现示例
    from torch.utils.checkpoint import checkpoint
    def forward(ctx, x):
        # 仅保留关键激活值
        ctx.save_for_backward(x)
        return model_block(x)
    # 前向计算时调用
    output = checkpoint(forward, inputs)
    ```
    
*   **显存-计算权衡**：

| 检查点间隔 | 显存占用 | 计算时间增加 |
| --- | --- | --- |
| 每层  | 20 GB | 35% |
| 每 2 层 | 28 GB | 20% |

* * *

六、应用选择指南
--------

### 综合决策矩阵

| 决策维度 | 技术选择优先级 |
| --- | --- |
| **数据规模** | 大数据→全量微调；小数据→PEFT |
| **硬件资源** | A 100≥8 卡→全量；≤4 卡→QLoRA |
| **任务多样性** | 多任务→LoRA/Prefix Tuning |
| **部署要求** | 低延迟→Adapter；高精度→SFT |

### 典型场景方案

1.  **对话系统开发**：
    
    ```text-plain
    graph LR
      PT(预训练模型) --> SFT 
      SFT --> RLHF
      RLHF --> Deploy
    ```
    
2.  **多任务 API 服务**：
    *   基座模型 + LoRA 多任务适配器
    *   动态加载不同 LoRA 权重（≈50 ms 切换时延）

* * *

七、总结与展望
-------

### 关键技术趋势

1.  **量化融合**：QLoRA 为代表的 4-bit 量化微调
2.  **自动化调优**：自动选择最优 PEFT 方法（AutoPEFT）
3.  **持续学习**：在不遗忘旧任务的前提下增量更新

### 实践建议

*   **中小规模企业**：优先采用 QLoRA+DeepSpeed 组合
*   **研究机构**：探索 MoE（Mixture of Experts）微调范式
*   **数据受限场景**：结合 Prompt Tuning 与知识蒸馏

### 参考文献

1.  Hu et al. "LoRA: Low-Rank Adaptation of Large Language Models" (2021)
2.  Lester et al. "The Power of Scale for Parameter-Efficient Prompt Tuning" (2021)
3.  Microsoft "DeepSpeed: Extreme-Scale Model Training" (2020)