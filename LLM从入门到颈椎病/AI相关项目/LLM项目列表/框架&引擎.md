# 框架&引擎
vLLM 🌟
-------

> vLLM是一个高吞吐量和内存高效的大型语言模型(LLMs)推理和服务引擎

[vLLM CPU和GPU模式署和推理 Qwen2 等大语言模型详细教程](https://mp.weixin.qq.com/s/KM-Z6FtVfaySewRTmvEc6w)

SGLang
------

> SGLang 是一个针对大型语言模型和视觉语言模型的快速服务框架。它通过共同设计后端运行时和前端语言，让您与模型的交互更快、更可控。核心功能包括：

*   **快速后端运行时**：通过 RadixAttention 提供高效的服务，用于前缀缓存、前跳约束解码、无开销 CPU 调度程序、连续批处理、令牌注意（分页注意）、张量并行、FlashInfer 内核、分块预填充和量化（FP8/INT4/AWQ/GPTQ）。
*   **灵活的前端语言**：为编程 LLM 应用程序提供直观的界面，包括链式生成调用、高级提示、控制流、多模式输入、并行性和外部交互。
*   **广泛的模型支持**：支持广泛的生成模型（Llama、Gemma、Mistral、QWen、DeepSeek、LLaVA 等）、嵌入模型（e5-mistral、gte、mcdse）和奖励模型（Skywork），并且易于扩展以集成新模型。
*   **活跃的社区**：SGLang 是开源的，并得到行业采用的活跃社区的支持。
*   使用文档

[SGLang Documentation — SGLang](https://sgl-project.github.io/)

*   博客

[SGLang v0.4: Zero-Overhead Batch Scheduler, Cache-Aware Load Balancer, Faster Structured Outputs | LMSYS Org](https://lmsys.org/blog/2024-12-04-sglang-v0-4/)

[GitHub - sgl-project/sglang: SGLang is a fast serving framework for large language models and vision language models.](https://github.com/sgl-project/sglang)