# 视频生成高频知识点
目录
--

*   [1.SG-I2V方法如何在预训练的视频扩散模型中实现特征的对齐？](#1.SG-I2V%E6%96%B9%E6%B3%95%E5%A6%82%E4%BD%95%E5%9C%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E8%A7%86%E9%A2%91%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%AE%9E%E7%8E%B0%E7%89%B9%E5%BE%81%E7%9A%84%E5%AF%B9%E9%BD%90%EF%BC%9F)
*   [2.在SG-I2V的潜在优化过程中，如何确保优化后的潜在变量不会偏离扩散过程的分布？](#2.%E5%9C%A8SG-I2V%E7%9A%84%E6%BD%9C%E5%9C%A8%E4%BC%98%E5%8C%96%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E5%A6%82%E4%BD%95%E7%A1%AE%E4%BF%9D%E4%BC%98%E5%8C%96%E5%90%8E%E7%9A%84%E6%BD%9C%E5%9C%A8%E5%8F%98%E9%87%8F%E4%B8%8D%E4%BC%9A%E5%81%8F%E7%A6%BB%E6%89%A9%E6%95%A3%E8%BF%87%E7%A8%8B%E7%9A%84%E5%88%86%E5%B8%83%EF%BC%9F)
*   [3.SG-I2V在实验中如何验证其有效性，使用了哪些评估指标？](#3.SG-I2V%E5%9C%A8%E5%AE%9E%E9%AA%8C%E4%B8%AD%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E5%85%B6%E6%9C%89%E6%95%88%E6%80%A7%EF%BC%8C%E4%BD%BF%E7%94%A8%E4%BA%86%E5%93%AA%E4%BA%9B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%EF%BC%9F)

1.SG-I2V方法如何在预训练的视频扩散模型中实现特征的对齐？
--------------------------------

**SG-I2V**通过对**自注意力层进行修改来实现特征的对齐**。具体来说，原始的SVD模型在每个帧上独立应用空间自注意力，这导致跨帧的特征对应关系较弱。 为了解决这个问题，**SG-I2V**将每个帧的自注意力层的键和值替换为第一帧的键和值，**从而使得所有帧的特征在语义上对齐**。 这种修改后的自注意力层能够更好地**捕捉跨帧的语义信息**，使得优化过程能够更有效地控制视频元素的轨迹。

2.在SG-I2V的潜在优化过程中，如何确保优化后的潜在变量不会偏离扩散过程的分布？
------------------------------------------

为了确保优化后的**潜在变量不会偏离扩散过程**的分布，**SG-I2V**采用了一种基于频率的后处理方法。 具体来说，使用快速傅里叶变换（FFT）和逆快速傅里叶变换（IFFT）来分离原始潜在变量zt∗的**低频和高频分量**。 然后，**保留低频分量， 并将高频分量替换为原始潜在变量的对应分量。** 这种方法有效地保留了**原始潜在的低频信号**，同时消除了可能引入的不必要的高频干扰，从而保持了生成视频的视觉质量。

3.SG-I2V在实验中如何验证其有效性，使用了哪些评估指标？
-------------------------------

**SG-I2V**在**VIPSeg数据集**的验证集上进行了评估。实验中使用了多种评估指标来验证其有效性，包括**Frechet Inception Distance（FID）、 Frechet Video Distance（FVD）和ObjMC**。**FID和FVD**用于衡量生成视频的视觉质量，而**ObjMC用于衡量运动保真度**。

具体来说，**FID和FVD越低，表示生成视频的质量越高**；**ObjMC越低，表示生成视频的运动越接近目标轨迹**。

实验结果表明，**SG-I2V**在视觉质量和运动保真度上都优于所有零样本基线方法，并且在某些指标上甚至与监督基线方法竞争。