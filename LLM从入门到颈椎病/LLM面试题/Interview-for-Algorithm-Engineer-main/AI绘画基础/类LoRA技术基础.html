<html>
  
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="../../../../style.css">
    <base target="_parent">
    <title data-trilium-title>类LoRA技术基础</title>
  </head>
  
  <body>
    <div class="content">
       <h1 data-trilium-h1>类LoRA技术基础</h1>

      <div class="ck-content">
        <hr />
        
<h2>created: 2025-01-25T00:41
updated: 2025-01-25T13:23</h2>

        
<h2>目录</h2>

        <ul>
          <li><a href="#1.%E4%BD%BF%E7%94%A8lora%E5%BE%AE%E8%B0%83Stable_Diffusion%E6%A8%A1%E5%9E%8B">1.使用lora微调Stable_Diffusion模型</a>
          </li>
          <li><a href="#2.%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E7%9A%84%E5%A4%9Alora%E7%BB%84%E5%90%88">2.用于图像生成的多lora组合</a>
          </li>
          <li><a href="#3.Hypernetwork%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F">3.Hypernetwork是什么？</a>
          </li>
          <li><a href="#4.HyperDreamBooth%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%EF%BC%882023%E5%B9%B47%E6%9C%88%E5%8F%91%E5%B8%83%EF%BC%89">4.HyperDreamBooth是什么？</a>
          </li>
          <li><a href="#5.DiffLoRA%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F(2024%E5%B9%B48%E6%9C%88%E5%8F%91%E5%B8%83)">5.DiffLoRA是什么？</a>
          </li>
          <li><a href="#6.AutoLoRA%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F">6.AutoLoRA是什么？</a>
          </li>
        </ul>
        
<h2>1.使用lora微调Stable_Diffusion模型</h2>

        <p><a href="https://arxiv.org/abs/2106.09685">LoRA: Low-Rank Adaptation of Large Language Models</a> 是微软研究员引入的一项新技术，主要用于处理大模型微调的问题。目前超过数十亿以上参数的具有强能力的大模型
          (例如 GPT-3) 通常在为了适应其下游任务的微调中会呈现出巨大开销。LoRA 建议冻结预训练模型的权重并在每个 Transformer 块中注入可训练层
          (<em>秩-分解矩阵</em>)。因为不需要为大多数模型权重计算梯度，所以大大减少了需要训练参数的数量并且降低了 GPU 的内存要求。研究人员发现，通过聚焦大模型的
          Transformer 注意力块，使用 LoRA 进行的微调质量与全模型微调相当，同时速度更快且需要更少的计算。</p>
        <p>LoRA也是一种微调 Stable Diffusion 模型的技术，其可用于对关键的图像/提示交叉注意力层进行微调。其效果与全模型微调相当，但速度更快且所需计算量更小。</p>
        <p>训练代码可参考以下链接：</p>
        <p><a href="https://huggingface.co/blog/zh/sdxl_lora_advanced_script">全世界 LoRA 训练脚本，联合起来! (huggingface.co)</a>
        </p>
        <p>
          <img src="api/images/skO1tLA8B0BQ/lORA.png" alt="image-20240611204740644"
          />
        </p>
        
<h2>2.用于图像生成的多lora组合</h2>

        <p>论文链接:<a href="https://arxiv.org/abs/2402.16843.pdf">https://arxiv.org/abs/2402.16843.pdf</a>
        </p>
        <p>
          <img src="api/images/3m9JWdxP5Ynj/多lora效果.png" alt="image-20240611203109836"
          />
        </p>
        
<h3><strong>LoRA Merge</strong>:</h3>

        <ul>
          <li>这种方法通过线性组合多个LoRAs来合成一个统一的LoRA，进而整合到文本到图像的模型中。</li>
          <li>主要优点是能够统一多个元素，但它的一个缺点是没有考虑到生成过程中与扩散模型的交互，可能导致像汉堡包和手指这样的元素在图像中变形。</li>
        </ul>
        
<h3><strong>LoRA Switch (LoRA-S)</strong>:</h3>

        <ul>
          <li>LoRA Switch旨在每个去噪步骤中激活单个LoRA，通过在解码过程中定时激活各个LoRA，引入了一种动态适应机制。</li>
          <li>图中用独特的颜色表示每个LoRA，每个步骤中只激活一个LoRA。</li>
          <li>这种方法允许在扩散模型的不同解码步骤中精确控制元素的影响，提高了生成图像的灵活性和控制精度。</li>
        </ul>
        
<h3><strong>LoRA Composite (LoRA-C)</strong>:</h3>

        <ul>
          <li>LoRA Composite探索在每个时间步骤中整合所有LoRA，而不是合并权重矩阵。</li>
          <li>它通过汇总每个LoRA在每一步的无条件和条件评分估计来实现，从而在图像生成过程中提供平衡的指导。</li>
          <li>这种方法有助于保持所有不同LoRA代表的元素的连贯整合，增强了图像的整体一致性和质量。</li>
        </ul>
        <p>
          <img src="api/images/7TaZTWIQMbcx/多lora生成.png" alt="image-20240611202719934"
          />
        </p>
        
<h2>3.Hypernetwork是什么？</h2>

        <p>Hypernetwork，也被称为“超网络”，是一种附加到 Stable Diffusion 模型的小型神经网络。它的主要作用是通过插入到噪声预测器
          UNet 的交叉注意力模块中，从而改变模型的风格表现。</p>
        
<h4>2. Hypernetwork 与其他模型的区别</h4>

        
<h5>Hypernetwork VS Checkpoint（大模型）</h5>

        <ul>
          <li><strong>Checkpoint 模型</strong>：包含生成图像的所有必要信息，文件体积较大，通常在 2 GB 到 7 GB 之间。</li>
          <li><strong>Hypernetwork</strong>：文件体积较小，通常低于 200 MB，但不能单独使用，必须与 Checkpoint
            模型配合才能生成图像。</li>
        </ul>
        
<h5>Hypernetwork VS LoRA 模型</h5>

        <ul>
          <li><strong>相似性</strong>：Hypernetwork 和 LoRA 模型在文件大小上相似，通常都在 200 MB 以下，比 Checkpoint
            模型要小。</li>
          <li><strong>效果对比</strong>：LoRA 模型一般能产生更好的效果，因此逐渐取代了 Hypernetwork 的位置。</li>
        </ul>
        
<h5>Hypernetwork VS Embeddings</h5>

        <ul>
          <li><strong>Embeddings</strong>：通过“文本反转”（Textual Inversion）技术生成，它定义新的关键词来实现特定风格，不会改变模型结构。Embeddings
            创建新的嵌入在文本编码器中。</li>
          <li><strong>Hypernetwork</strong>：通过将一个小型网络插入到噪声预测器的交叉注意力模块中来改变模型的输出风格。</li>
        </ul>
        
<h4>3. Hypernetwork 的现状</h4>

        <ul>
          <li><strong>使用减少</strong>：由于 LoRA 和 Embeddings 的出现，Hypernetwork 的使用频率逐渐下降。在一些社区资源库中，Hypernetwork
            文件数量非常有限。</li>
          <li><strong>效果有限</strong>：虽然 Hypernetwork 的文件体积较大，但其效果往往不如更小的 Embeddings 文件，而这些效果可以通过其他方式实现，例如使用
            Embeddings 或 LoRA 模型。</li>
        </ul>
        
<h2>4.HyperDreamBooth是什么？(2023年7月发布)</h2>

        <p>论文链接：<a href="https://arxiv.org/pdf/2307.06949">https://arxiv.org/pdf/2307.06949</a>
        </p>
        <p>这篇论文提出了一种名为 HyperDreamBooth 的新方法,用于快速和轻量级的主体驱动个性化文本到图像扩散模型。主要内容包括:</p>
        <ol>
          <li>
            <p><strong>轻量级 DreamBooth (LiDB)</strong>: 提出了一种新的低维权重空间,用于模型个性化,可以将个性化模型的大小减少到原始
              DreamBooth 的 0.01%。</p>
          </li>
          <li>
            <p><strong>超网络架构</strong>: 设计了一个超网络,可以从单个图像生成 LiDB 参数。超网络由 ViT 编码器和 Transformer
              解码器组成。</p>
          </li>
          <li>
            <p><strong>rank-relaxed 快速微调</strong>: 提出了一种技术,可以在几秒钟内显著提高输出主体的保真度。</p>
          </li>
          <li>
            <p>性能</p>
            <p>: 与 DreamBooth 和 Textual Inversion 等方法相比,HyperDreamBooth 在速度和质量上都有显著提升:</p>
            <ul>
              <li>速度提高了 25 倍</li>
              <li>模型大小减少了 10000 倍</li>
              <li>在主体保真度和风格多样性方面取得了相当或更好的结果</li>
            </ul>
          </li>
        </ol>
        <p>整体框架如下图：</p>
        <p>
          <img src="api/images/kggJCvo7QVRa/HyperDreamBooth.png" alt="image-20240902192807641"
          />
        </p>
        <p>Lightweight DreamBooth结构如下：</p>
        <p>![image-20240902193005109](./imgs/Lightweight DreamBooth.png)</p>
        <p>HyperDreamBooth 实现了快速、轻量级和高质量的文本到图像模型个性化,为创意应用开辟了新的可能性。</p>
        
<h2>5.DiffLoRA是什么？(2024年8月发布)</h2>

        <p>论文链接：<a href="https://arxiv.org/pdf/2408.06740">https://arxiv.org/pdf/2408.06740</a>
        </p>
        <p>DiffLoRA框架包含以下关键组成部分:</p>
        <ol>
          <li>LoRA权重自动编码器(LAE):将LoRA权重压缩到隐空间并进行重构。LAE采用1D卷积层作为主要压缩层,并引入权重保留损失来提高重构精度。</li>
          <li>混合图像特征(MIF):利用MoE启发的门控网络,将人脸特征和图像特征相结合,更好地提取身份信息。</li>
          <li>去噪过程:使用DiT架构和条件集成,通过迭代去噪生成LoRA隐表示。</li>
          <li>LoRA权重数据集构建:自动化流程生成多身份LoRA权重数据集,用于训练DiffLoRA。</li>
        </ol>
        <p>整体框架如下图：</p>
        <p>
          <img src="api/images/HBgdIIDG8OjD/difflora.png" alt="difflora" />
        </p>
        <p>MIF结构图:</p>
        <p>
          <img src="api/images/NY8MFoDDpkAe/MIF.png" alt="MIF" />
        </p>
        <p>这是一种利用扩散模型作为超网络来根据参考图像预测个性化低秩适应（LoRA）权重的方法。通过将这些 LoRA 权重集成到文本到图像模型中，DiffLoRA
          无需进一步训练即可在推理过程中实现个性化。这是第一个利用扩散模型来生成面向身份的 LoRA 权重的模型</p>
        
<h2>6.AutoLoRA是什么？(2024年10月发布)</h2>

        <p>论文链接：<a href="https://arxiv.org/pdf/2410.03941">2410.03941</a>
        </p>
        
<h3>1. <strong>方法概述</strong></h3>

        <p>AutoLoRA 是一种提升扩散模型生成图像多样性和质量的新方法，主要结合了 <strong>LoRA (低秩适应)</strong> 和 <strong>AutoGuidance</strong> 技术：</p>
        <ul>
          <li><strong>LoRA</strong>：通过对大模型进行低秩微调，使其能够适应特定风格或领域，但通常由于训练数据有限，模型容易过拟合，导致生成图像的多样性不足。</li>
          <li><strong>AutoGuidance</strong>：通过让训练不足的模型版本指导完全训练的模型，从而在生成过程中引入更多多样性。</li>
        </ul>
        <p>AutoLoRA 结合了这两者的思路，通过让基础模型与 LoRA 微调模型共同指导图像生成，从而实现了在一致性和多样性之间的平衡。</p>
        
<h3>2. <strong>核心机制</strong></h3>

        <ul>
          <li>
            <p><strong>指导机制</strong>：AutoLoRA 通过在每一步生成中，将基础模型 <code>ϵ(xt, y)</code> 和 LoRA
              微调后的模型 <code>ϵLoRA(xt, y)</code> 的输出结合起来，控制生成的多样性： $$ \epsilon_{\mathrm{\Lambda
              utoLoRA}}^{\gamma}(\mathbf{x}_t,y)=\epsilon(\mathbf{x}<em>t,y)+\gamma\cdot(\epsilon</em>{\mathrm{LoR\Lambda}}(\mathbf{x}_t,y)-\epsilon(\mathbf{x}_t,y)),
              $$ 其中 <code>γ</code> 是调节参数，决定了生成图像中基础模型多样性和 LoRA 模型适应性之间的平衡。</p>
          </li>
          <li>
            <p><strong>无分类器指导 (CFG)</strong>：AutoLoRA 为基础模型和 LoRA 微调模型分别应用 CFG，进一步提升生成过程中的控制力和多样性。</p>
          </li>
        </ul>
        <p>
          <img src="api/images/A1CrcNeQ3hSM/autolora效果.png" alt="image-20241021173657563"
          />
        </p>
        
<h3>3. <strong>关键思想</strong></h3>

        <ul>
          <li><strong>多样性与一致性的平衡</strong>：通过结合基础和微调模型的输出，AutoLoRA 能在保留特定风格一致性的同时引入更多多样性。这解决了
            LoRA 模型因小数据集训练导致的过拟合问题。</li>
          <li><strong>双重指导</strong>：单独为基础和微调模型应用 CFG，有助于增加生成图像的细节和质量，同时维持对输入提示的良好响应。</li>
          <li><strong>探索与利用</strong>：AutoLoRA 的设计类似于在探索（生成多样性）和利用（保持风格一致性）之间寻找最优点，使得生成的图像既符合预期风格，又能展示丰富的细节变化。</li>
        </ul>
      </div>
    </div>
  </body>

</html>