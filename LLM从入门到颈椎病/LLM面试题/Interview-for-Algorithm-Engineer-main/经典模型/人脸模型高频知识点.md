# 人脸模型高频知识点
目录
--

*   [1.传统Softmax，做人脸识别任务的问题](#user-content-1.%E4%BC%A0%E7%BB%9FSoftmax%EF%BC%8C%E5%81%9A%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%BB%BB%E5%8A%A1%E7%9A%84%E9%97%AE%E9%A2%98)
*   [2.何为只有分类能力，没有判别能力](#user-content-2.%E4%BD%95%E4%B8%BA%E5%8F%AA%E6%9C%89%E5%88%86%E7%B1%BB%E8%83%BD%E5%8A%9B%EF%BC%8C%E6%B2%A1%E6%9C%89%E5%88%A4%E5%88%AB%E8%83%BD%E5%8A%9B)
*   [3.L-Softmax（ICML 2016）](#user-content-3.L-Softmax)
*   [4.SphereFace（ICML 2016）](#user-content-4.SphereFace)
*   [5.CosFace（CVPR 2018）](#user-content-5.CosFace)
*   [6.ArcFace（CVPR 2019）](#user-content-6.ArcFace)
*   [7.CurricularFace（CVPR 2020）](#user-content-7.CurricularFace)
*   [8.AdaFace（CVPR 2022）](#user-content-8.AdaFace)

1.传统Softmax，做人脸识别任务的问题
----------------------

Softmax一般用于闭集（训练集包含全部类别）分类任务的损失函数，但是人脸识别场景下，每个人的人脸都是不同的，训练集无法涵盖全部类别，因此属于开集任务，需要采用度量学习的方式来实现，度量学习即通过比对不同人的特征相似程度，来判断是否属于同一人，而Softmax只有分类的能力没有判别能力，因此不适用于人脸识别任务。

![](api/images/Vzf2kHy2vvOO/FR_1.png)

2.何为只有分类能力，没有判别能力
-----------------

![](api/images/1jTwR09iTtMZ/FR_2.png)

如图所示绘制了度量学习与分类，从图上可以看出两类样本可以被一个分界面清晰地分开，但这个分界面的两侧的样本之间的距离（黄色箭头）可能会非常小，有可能会远小于类内样本之间的距离（蓝色箭头）。由此可见，度量学习要求更高的类间间隔。在分类问题中，往往也会要求训练类别之间拉开一定的间隔，然而这个间隔是为了提升模型的泛化能力、减小结构风险而引入的。在度量学习中，即使不考虑泛化性能只在训练集上进行度量也仍旧需要非常大的间隔，而分类任务如果不考虑泛化误差，其间隔甚至可以为0，这也就意味着度量学习是比分类更加困难的任务。

我们希望网络输出的特征，类间的最小距离，要大于类内最大距离，那么这就是一个非常好的特征分布，即类内间距尽可能小，类间间距尽可能大，目前绝大多数的Paper都是针对这里进行的改进。

3.L-Softmax（ICML 2016）
----------------------

Paper：Large-Margin Softmax Loss for Convolutional Neural Networks

Code：[https://github.com/wy1iu/LargeMargin\_Softmax\_Loss](https://github.com/wy1iu/LargeMargin_Softmax_Loss)

![](api/images/jqAw8L3l0I0H/FR_3.png)

创新点：

作者认为，既然要采用度量学习，那么就要专注于优化特征向量之间的夹角，因此去掉了softmax中的bias，其次作者引入了一个乘数m，来迫使类内更加紧凑

从决策边界理解损失函数设计：

以二分类为例，Softmax的决策边界为：||w1||cosθ1=||w2||cosθ2，其中θ为x与w的夹角，当w模长相同时，显然当θ1 < θ2，为第一类。

L-Softmax的决策边界为：||w1||cos(mθ1)=||w2||cosθ2，其中θ为x与w的夹角，当w模长相同时，显然mθ1 < θ2时，为第一类，由于m>1，则有θ1<θ2/m，因此得到一个更紧凑的决策边界。

![](api/images/YSf7ImAWpjjW/FR_4.png)

4.SphereFace（ICML 2016）
-----------------------

SphereFace（ICML 2016） Paper：SphereFace: Deep Hypersphere Embedding for Face Recognition

Code：[https://github.com/wy1iu/sphereface](https://github.com/wy1iu/sphereface)

![](api/images/gQ2VgfG1Z7XL/FR_5.png)

创新点：

可以发现，SphereFace和L-Softmax 为同一作者，作者认为由于权重w模的大小不同会影响梯度的分配，因此作者将权重w进行了归一化

**决策边界**：cos(mθ1)=cosθ2

5.CosFace（CVPR 2018）
--------------------

Paper：CosFace: Large Margin Cosine Loss for Deep Face Recognition

Code：[https://github.com/Tencent/TFace](https://github.com/Tencent/TFace)

![](api/images/FnvFn5gJo3Ak/FR_6.png)

创新点：

作者发现，SphereFace中，当θ非常小时，无论乘以多大的Margin，得到的值依然很小，因此作者将乘性的margin变成加性的margin，这样无论θ的大小，均可以得到一个恒定的决策边界Margin，即cos(mθ)变为cos(θ - m) ，改进后为了解决收敛问题，引入了伸缩系数s，固定||x|| = s

**决策边界**：cos(θ1-m)=cosθ2

![](api/images/cJ4YocOA90Yv/FR_7.png)

6.ArcFace（CVPR 2019）
--------------------

Paper：ArcFace: Additive Angular Margin Loss for Deep Face Recognition

Code：[https://github.com/deepinsight/insightface](https://github.com/deepinsight/insightface)

![](api/images/yLXwgYC6EYrE/FR_8.png)

创新点：

作者在CosFace Loss上做了一处改进，将margin从余弦空间转换到角度空间，能够获得更好的几何解释,ArcFace 的角边距对应于超球面表面上的弧边距（测地线距离）。

**决策边界**：cos(θ1+m)=cosθ2

![](api/images/dVs2lDFxY2lL/FR_9.png)

7.CurricularFace（CVPR 2020）
---------------------------

Paper：CurricularFace: Adaptive Curriculum Learning Loss for Deep Face Recognition

Code：[https://github.com/HuangYG123/CurricularFace](https://github.com/HuangYG123/CurricularFace)

![](api/images/3jRG3XjAB9gd/FR_10.png)

![](api/images/Exl0Hg2Uru50/FR_11.png)

创新点：

作者发现，样本可以分为简单样本和困难样本，在之前的人脸损失函数中，它们没有考虑每个样本的难度，均使用相同的权重去优化，而CurricularFace的思想就是在训练时前期先强调容易的样本，后期再强调困难样本，并且根据困难样本的程度，分配不同的权重。

简单样本：特征向量与全部负样本权重的夹角，均大于特征向量与正样本权重的夹角（分类正确）

困难样本：特征向量与某负样本权重的夹角，小于特征向量与正样本权重的夹角（分类出错）

**注意**：这个夹角也可以结合margin base 来计算，即计算时加上margin，会更严格，例如arcface，此时分类正确的样本可能是困难样本！

**参数t的设定**：在早期训练阶段，从简单样本中学习有利于模型收敛。因此，t应该接近于零，t+cosθj小于1。因此，减少了硬样本的权重，并相对强调了容易的样本。随着训练的进行，模型逐渐聚焦于难样本，即t的值应增加，t+cosθj大于1。因此，用较大的权重强调硬样本。文中将t设为自适应参数，根据一个batch中的正样本cosθ均值来确定，考虑到个别batch中可能含有大量极端数据，为了稳定采用指数移动平均法来计算。

此外，在参数t固定时，t+cosθj也会根据θ夹角，动态调整，θ越小越困难，t+cosθj会整体变大，

这是该论文双重自适应的由来，一个是t的自适应，一个是θ的自适应。

**决策边界**：cos(θyi + m) = cos θj (easy) cos(θyi + m) = (t + cos θj ) cos θj (hard)

![](api/images/EojFn6tYL1lk/FR_12.png)

8.AdaFace（CVPR 2022）
--------------------

Paper：AdaFace: Quality Adaptive Margin for Face Recognition

Code：[https://github.com/mk-minchul/AdaFace](https://github.com/mk-minchul/AdaFace)

![](api/images/L1tDPQgkSgxV/FR_13.png)

![](api/images/PYWHcrhiqaBM/FR_14.png)

![](api/images/Nq1azxzaCVYt/FR_15.png)

![](api/images/pTzBOMqFVz5k/FR_16.png)

创新点：

作者认为，不能单纯的根据难易样本来区分权重，例如训练数据中可能含有噪音数据，他被分类为难样本，模型会提高权重去优化，然而优化噪音数据可能会导致模型效果变差。因此作者提出，应该根据图像质量来区别对待难易样本，在图像高质量时强调难样本，在图像低质量时，强调简单样本，作者发现，特征向量的范数与图像质量呈正相关，即范数越大，图像质量往往越高。

同时作者发现，CosFace，ArcFace，以及CurricularFace，对难易样本优化的权重有所不同，详细见下图，作者结合了这几个损失函数的特性，基于特征范数值自适应地改变裕值函数，当范数较大时，会对远离决策边界的样本分配较大的权重，当范数较低时，则强调靠近决策边界的样本。

![](api/images/pJnT9bjgAT6G/FR_17.png)